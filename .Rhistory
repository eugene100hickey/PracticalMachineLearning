curve(max(hist$counts)/0.4*dnorm(x, 0, 1), -3, 3, col = "blue", add = TRUE)
?chisq
??chisq
?Chisquare
qchisq(0.025, 26)
lower <- sqrt((samplSize-1)sd(mns)/qchisq(0.025, 3))
lower <- sqrt((samplSize-1)*sd(mns)/qchisq(0.025, 3))
lower <- sqrt((sampleSize-1)*sd(mns)/qchisq(0.025, 3))
lower
variance <- c(var(mns), 1/(lambda)^2/(40-1))
set.seed(314159)
lambda = 0.2
sampleNo = 1000
sampleSize = 40
data <- matrix((rexp(sampleNo*sampleSize, lambda)),
nrow=sampleNo,
ncol=sampleSize,
byrow=TRUE)
mns = apply(X=data, MARGIN=1, FUN=mean)
variance <- c(var(mns), 1/(lambda)^2/(40-1))
variance
lower <- sqrt((sampleSize-1)*sd(mns)/qchisq(0.025, 3))
lower
sd(mns)
qchisq(0.025, 3)
qchisq(0.025, 39)
lower <- sqrt((sampleSize-1)*sd(mns)/(qchisq(0.025, 39)^2))
lower
upper <- sqrt((sampleSize-1)*sd(mns)/(qchisq(0.975, 39)^2))
upper
qchisq(0.025, 39)
qchisq(0.975, 39)
upper <- (sampleSize-1)*sd(mns)/(qchisq(0.025, 39)^2)
lower <- (sampleSize-1)*sd(mns)/(qchisq(0.975, 39)^2)
upper
lower
variance
lower <- (sampleSize-1)*sd(mns)^2/(qchisq(0.975, 39)^2)
lower
sd(mns)
sd(mns)^2
qchisq(p=0.975, df=26)
qchisq(p=0.025, df=26)
qchisq(p=0.025, df=39)
qchisq(p=0.975, df=39)
lower <- (sampleSize-1)*sd(mns)^2/(qchisq(0.975, 39))
lower
lower <- (sampleSize-1)*sd(mns)^2/(qchisq(0.025, 39))
lower
variance <- c(var(mns), 1/(lambda)^2/(40-1))
names(variance) <- c("Observed Variance", "    Theoretical Variance")
chisquared[1] = (sampleSize-1)*sd(mns)^2/(qchisq(0.975, 39))
chisquared[2] = (sampleSize-1)*sd(mns)^2/(qchisq(0.025, 39))
text <- paste("The Confidence Interval for the Variance is from ",
round(chisquared[1], 2),
" to ",
round(chisquared[2], 2))
variance
text
chisquared[1] = (sampleSize-1)*sd(mns)^2/(qchisq(0.975, 39))
variance <- c(var(mns), 1/(lambda)^2/(40-1))
names(variance) <- c("Observed Variance", "    Theoretical Variance")
chisq_upper = (sampleSize-1)*sd(mns)^2/(qchisq(0.975, 39))
chisq_lower = (sampleSize-1)*sd(mns)^2/(qchisq(0.025, 39))
text <- paste("The Confidence Interval for the Variance is from ",
round(chisq_lower, 2),
" to ",
round(chisq_upper, 2))
variance
text
?wilks
?shapiro.test
shapiro(mns)
shapiro.test(mns)
qqnorm(mns)
line(x~y)
?line
line(x=c(-3, 3), y=c(3, 7))
qq <- qqnorm(mns)
qq
class(qq)
dim(qq)
qq[1]
qq[2]
qq[3]
?lm
lm(qq)
?hist
hist = hist(mns, breaks = 30, prob=TRUE)
normal_scale = max(hist$counts)/0.4
# this is match the amplitude of the histogram to normal function
curve(dnorm(x, 0, 1), -3, 3, col = "blue", add = TRUE)
abline(v=0, lwd=5, lty=2, col="red")
legend("topright",
legend=c("theoretical mean", "normal distribution"),
lty=c(2, 1),
lwd=c(5,1),
col=c("red", "blue"))
shapiro.test(mns)
res <- shapiro.test(mns)
res
rm(list=ls())
newdata <- rnorm(1000)
shapiro.test(newdata)
newdata <- rnorm(10000)
shapiro.test(newdata)
newdata <- rnorm(5000)
shapiro.test(newdata)
?shapiro.test
?qnorm
qqnorm(mns)
set.seed(314159)
lambda = 0.2
sampleNo = 1000
sampleSize = 40
data <- matrix((rexp(sampleNo*sampleSize, lambda)),
nrow=sampleNo,
ncol=sampleSize,
byrow=TRUE)
mns = apply(X=data, MARGIN=1, FUN=mean)
qqnorm(mns)
?qqline
qqline(mns)
qqnorm(mns)
qqline(mns, col="red", lwd=3, lty=7)
?pch
qqnorm(mns, pch=19)
qqnorm(mns, pch=19, col = "lightblue")
qqnorm(mns, pch=1, col = "lightblue")
qqnorm(mns, pch=1, col = "lightblue", lwd=2)
qqline(mns, col="red", lwd=3, lty=7)
legend("topright",
legend=c("sample means", "normal distribution"),
lty=c(2, 1),
lwd=c(2,1),
pch = c(1, 1)
col=c("black", "red"))
legend=c("sample means", "normal distribution"),
legend("topright",
lty=2
lwd=2,
pch = 1
legend=c("sample meansnormal distribution"),
col=c("black"))
legend("topright",
lty=2
lwd=2,
pch = 1
legend="sample meansnormal distribution",
col="black")
4
par(mfrow=c(1,2))
qplot(len, data=ToothGrowth, binwidth=2, fill=as.factor(dose), facets = supp~.)
qplot(len, data=ToothGrowth, geom="density", color=supp, facets = dose~.)
library(ggplot2)
par(mfrow=c(1,2))
qplot(len, data=ToothGrowth, binwidth=2, fill=as.factor(dose), facets = supp~.)
qplot(len, data=ToothGrowth, geom="density", color=supp, facets = dose~.)
library(gridExtra)
plot1 = qplot(len, data=ToothGrowth, binwidth=2, fill=as.factor(dose), facets = supp~.)
plot2 = qplot(len, data=ToothGrowth, geom="density", color=supp, facets = dose~.)
grid.arrange(plot1, plot2, ncol=2
plot1 = qplot(len, data=ToothGrowth, binwidth=2, fill=as.factor(dose), facets = supp~.)
plot2 = qplot(len, data=ToothGrowth, geom="density", color=supp, facets = dose~.)
grid.arrange(plot1, plot2, ncol=2)
plot1 = qplot(len, data=ToothGrowth, binwidth=2, fill=as.factor(dose), facets = supp~.)
plot2 = qplot(len, data=ToothGrowth, geom="density", color=supp, facets = dose~.)
grid.arrange(plot1, plot2, nrow=2)
data("ToothGrowth")
?qplot
plot2 = qplot(len, data=ToothGrowth, geom="density", color=supp, ylab="", facets = dose~.)
plot2
t.test(len ~ dose, paired = FALSE, var.equal = FALSE, data = ToothGrowth)$conf)
t.test(len ~ dose, paired = FALSE, var.equal = FALSE, data = ToothGrowth)$conf
data("ChickWeight")
t.test(gain ~ Diet, paired = FALSE, var.equal = FALSE, data = wideCW14)$conf
wideCW <- dcast(ChickWeight, Diet + Chick ~ Time, value.var = "weight")
names(wideCW)[-(1 : 2)] <- paste("time", names(wideCW)[-(1 : 2)], sep = "")
library(dplyr)
wideCW <- mutate(wideCW,
gain = time21 - time0
)
wideCW <- dcast(ChickWeight, Diet + Chick ~ Time, value.var = "weight")
library(dplyr)
wideCW <- dcast(ChickWeight, Diet + Chick ~ Time, value.var = "weight")
library(reshape2)
wideCW <- dcast(ChickWeight, Diet + Chick ~ Time, value.var = "weight")
names(wideCW)[-(1 : 2)] <- paste("time", names(wideCW)[-(1 : 2)], sep = "")
wideCW <- mutate(wideCW,
gain = time21 - time0
)
wideCW14 <- subset(wideCW, Diet %in% c(1, 4))
t.test(gain ~ Diet, paired = FALSE, var.equal = TRUE, data = wideCW14)$conf
View(ChickWeight)
View(wideCW14)
ibrary(pander)
ts <- lapply(c(.5, 1, 2), function(x) {
t.test(len ~ supp, data=subset(ToothGrowth, dose==x), paired=FALSE, var.equal=FALSE)
})
pvals <- c(ts[[1]]$p.value, ts[[2]]$p.value, ts[[3]]$p.value)
stats <- c(ts[[1]]$statistic, ts[[2]]$statistic, ts[[3]]$statistic)
adjp <- p.adjust(pvals, method = "bonferroni")
lls <- sapply(c(ts[[1]]$conf.int[1], ts[[2]]$conf.int[1], ts[[3]]$conf.int[1]), round, 3)
uls <- sapply(c(ts[[1]]$conf.int[2], ts[[2]]$conf.int[2], ts[[3]]$conf.int[2]), round, 3)
df <- data.frame(dose=c(0.5, 1, 2), t=stats, p=pvals, adj=adjp,
ci=paste0("[",paste(lls, uls, sep=", "), "]"))
colnames(df) <- c("Dose", "t", "p-value", "adj. p-value", "conf. int.")
pander(df, round=3, split.tables=120,
caption="*Two-sided comparison of delivery methods by dose*")
library(pander)
??pander
install.packages("pander")
library(pander)
library(pander)
ts <- lapply(c(.5, 1, 2), function(x) {
t.test(len ~ supp, data=subset(ToothGrowth, dose==x), paired=FALSE, var.equal=FALSE)
})
pvals <- c(ts[[1]]$p.value, ts[[2]]$p.value, ts[[3]]$p.value)
stats <- c(ts[[1]]$statistic, ts[[2]]$statistic, ts[[3]]$statistic)
adjp <- p.adjust(pvals, method = "bonferroni")
lls <- sapply(c(ts[[1]]$conf.int[1], ts[[2]]$conf.int[1], ts[[3]]$conf.int[1]), round, 3)
uls <- sapply(c(ts[[1]]$conf.int[2], ts[[2]]$conf.int[2], ts[[3]]$conf.int[2]), round, 3)
df <- data.frame(dose=c(0.5, 1, 2), t=stats, p=pvals, adj=adjp,
ci=paste0("[",paste(lls, uls, sep=", "), "]"))
colnames(df) <- c("Dose", "t", "p-value", "adj. p-value", "conf. int.")
pander(df, round=3, split.tables=120,
caption="*Two-sided comparison of delivery methods by dose*")
?t.test
t.test(len~supp, data=ToothGrowth)
dose = unique(ToothGrowth$dose)
supp = levels(ToothGrowth$supp)
doses <- subset(ToothGrowth, ToothGrowth$supp == dose)
doses
doses <- subset(ToothGrowth, ToothGrowth$dose == dose)
for(i in 1:3) {doses[i] <- subset(ToothGrowth, ToothGrowth$dose == dose[i])}
View(doses)
for(i in 1:3) {doses[,i] <- subset(ToothGrowth, ToothGrowth$dose == dose[i])}
View(doses)
doses=NULL
for(i in 1:3) {doses[,i] <- subset(ToothGrowth, ToothGrowth$dose == dose[i])}
doses <- c(1:)
subset(ToothGrowth, ToothGrowth$dose == dose[1])
dose$half <- subset(ToothGrowth, ToothGrowth$dose == dose[1])
dose
dose_half = subset(ToothGrowth, ToothGrowth$dose == 0.5)
dose_one = subset(ToothGrowth, ToothGrowth$dose == 1.0)
dose_two = subset(ToothGrowth, ToothGrowth$dose == 2.0)
t.test(dose_half, dose_one)
?t.test
t.test(x=dose_half, y=dose_one, paired=FALSE, var.equal=FALSE)
dose_half
t.test(x=dose_half$len, y=dose_one$len, paired=FALSE, var.equal=FALSE)
t.test(x=dose_one$len, y=dose_two$len, paired=FALSE, var.equal=FALSE)
dose_one_oj = subset(dose_one, dose_one$supp == 'OJ')
dose_two_oj = subset(dose_two, dose_one$supp == 'OJ')
t.test(x=dose_one_oj$len, y=dose_two_oj$len, paired=FALSE, var.equal=FALSE)
t = t.test(x=dose_one_oj$len, y=dose_two_oj$len, paired=FALSE, var.equal=FALSE)
t$p.value
?round
oj <- subset(ToothGrowth, ToothGrowth$supp == 'OJ')
vc <- subset(ToothGrowth, ToothGrowth$supp == 'VC')
dose_half_oj= subset(dose_half, dose_half$supp == 'OJ')
dose_one_oj = subset(dose_one, dose_one$supp == 'OJ')
dose_two_oj = subset(dose_two, dose_one$supp == 'OJ')
dose_half_vc= subset(dose_half, dose_half$supp == 'VC')
dose_one_vc = subset(dose_one, dose_one$supp == 'VC')
dose_two_vc = subset(dose_two, dose_one$supp == 'VC')
delivery_test_half=t.test(x=dose_half_oj$len, y=dose_half_vc$len, paired=FALSE, var.equal=FALSE)
delivery_test_one = t.test(x=dose_one_oj$len, y=dose_one_vc$len, paired=FALSE, var.equal=FALSE)
delivery_test_two = t.test(x=dose_two_oj$len, y=dose_two_vc$len, paired=FALSE, var.equal=FALSE)
delivery_test_one
delivery_test_two
delivery_test_half
?t.test
length_test_1 = t.test(x=dose_half$len, y=dose_one$len, alternative = c("one.sided", "less"), paired=FALSE, var.equal=FALSE)
length_test_1 = t.test(x=dose_half$len, y=dose_one$len, alternative = c("less"), paired=FALSE, var.equal=FALSE)
length_test_1
signif(length_test_1$conf.int[1], 3)
length_test_1 = t.test(x=dose_half$len, y=dose_one$len, alternative = c("less"), paired=FALSE, var.equal=FALSE)
signif(length_test_1$conf.int[1], 3)
dose_half = subset(ToothGrowth, ToothGrowth$dose == 0.5)
dose_one = subset(ToothGrowth, ToothGrowth$dose == 1.0)
dose_two = subset(ToothGrowth, ToothGrowth$dose == 2.0)
length_test_1 = t.test(x=dose_half$len, y=dose_one$len, alternative = c("less"), paired=FALSE, var.equal=FALSE)
signif(length_test_1$conf.int[1], 3)
length_test_1
length_test_1
length_test_1$p.value
signif(length_test_1$p.value, 4)
library(caret)
library(knitr)
library(rJava)
library(extraTrees)
library(gplots)
library(rpart)
library(rattle)
seedvalue=27183
set.seed(seedvalue)
setwd("C:/Users/Eugene/Desktop/Coursera/08 Practical Machine Learning/Project")
train.data = read.csv2("pml-training.csv", sep=",")
test.data = read.csv2("pml-testing.csv", sep=",")
#remove empty columns from test data
test.data = test.data[,colSums(is.na(test.data))<nrow(test.data)]
#remove problem_id column and initial boring columns from test data that just counts from 1:20
test.data = test.data[,-c((1:7),60)]
#give train data same columns as test data, but with classe column (160) added
train.data = train.data[,c(which(names(train.data) %in% names(test.data)), 160)]
#splitting into a training and validation sets
intrain = createDataPartition(y=train.data$classe, p=0.7, list=F)
training=train.data[intrain,]
valid = train.data[-intrain,]
train.x = training[,-53]
train.x = sapply(train.x, FUN=as.numeric)
means = apply(train.x, MARGIN=2, FUN=mean)
sds = apply(train.x, MARGIN=2, FUN=sd)
train.xt = train.x[,(abs(sds/means)>1.5)]
train.xt = as.data.frame(train.xt)
train.xt = cbind(train.xt, training$classe)
names(train.xt)[length(train.xt)] = "classe"
plot(abs(sds/means))
abline(h=1.5, col="red", lwd=2)
library(tree)
install.packages("tree")
library(tree)
model.tree = tree(classe~., data = train.xt)
plot(model.tree)
text(model.tree)
plot(model.tree)
text(model.tree, cex=0.4)
plot(model.tree)
text(model.tree, cex=0.5)
plot(model.tree)
text(model.tree, cex=0.6)
summary(tree())
summary(model.tree)
model.tree
summary(model.tree)
pred.tree = predict(model.tree, valid)
confusionMatrix(pred.tree, valid$classe)
summary(pred.tree)
table(pred.tree)
confusionMatrix(pred.tree, valid1$classe)
valid1 = valid[c(which(names(valid1) %in% names(train.xt)))]
valid1 = valid[c(which(names(valid) %in% names(train.xt)))]
confusionMatrix(pred.tree, valid1$classe)
pred.tree = predict(model.tree, valid1)
cm.tree = confusionMatrix(pred.tree, valid1$classe)
levels(valid1$classe)
levels(pred.tree)
summary(pred.tree)
cm.tree = confusionMatrix(valid1$classe, pred.tree)
pref.tree
pred.tree
model.tree = tree(classe~., method = "class", data = train.xt)
pred.tree = predict(model.tree, valid1)
pred.tree
?tree
model.tree$y
model.tree$where
model.tree$terms
confusionMatrix(model.tree$y, train.xt$classe)
pred.tree = predict(model.tree, valid1, type = "class")
cm.tree = confusionMatrix(valid1$classe, pred.tree)
cm.tree
fancyRpartPlot(model.tree, cex = 0.5)
plot(model.tree, cex=0.5)
plot(model.tree)
text(model.tree, cex=0.5)
cm.tree$overall
cm.tree$overall[1]
cm.tree$overall[[1]]
signif(cm.tree$overall[[1]], 2)
library(party)
model.ctree = ctree(class~.,data=train.xt)
model.ctree = ctree(class~.,data=as.matrix(train.xt))
model.ctree = ctree(class~.,data=as.data.frame(train.xt))
?ctree
modfit.rf = train(classe~.,data=train.xt,
method="rf",
trControl = trainControl(method = "cv", number = 3),
allowParallel=T)
pred.rf10 = predict(modfit.rf, valid1)
cm.rf10 = confusionMatrix(valid1$classe, pred.rf)
cm.rf10 = confusionMatrix(valid1$classe, pred.rf10)
summary(cm.rf10)
cm.rf10$overall
cm.rf10$overall[[1]]
cm.rf10
table(cm.rf10)
modfit.gbm = train(classe ~ ., data=train.xt, method = "gbm",
trControl = trainControl(method="repeatedcv",number=5, repeats=1),
verbose = FALSE,
allowParallel=T)
modfit.gbm = train(classe ~ ., data=train.xt, method = "gbm",
trControl = trainControl(method="repeatedcv",number=5, repeats=1),
allowParallel=T)
modfit.gbm = train(classe ~ ., data=train.xt, method = "gbm",
trControl = trainControl(method="repeatedcv",number=5, repeats=1),
verbose = FALSE,
allowParallel=T)
?gbm
modelLookup("gbm")
modfit.gbm
training.x = sapply(training, FUN=as.numeric)
testing.x = sapply(testing, as.numeric)
modfit.XTrees= extraTrees(x=training.x, y = training[,53], na.action = "zero")
pred.XTrees = predict(modfit.XTrees, testing.x)
modfit.XTrees$factor
modfit.XTrees$ntree
modfit.XTrees$levels
cm.XTrees
pred.XTrees = predict(modfit.XTrees, valid.x)
valid.x = sapply(valid, as.numeric)
pred.XTrees = predict(modfit.XTrees, valid.x)
cm.XTrees = confusionMatrix(valid1$classe, pred.XTrees)
cm.XTrees
modfit.gbm = train(classe ~ ., data=train.xt, method = "gbm",
trControl = trainControl(method="repeatedcv",number=5, repeats=1),
verbose = FALSE)
pred.gbm = predict(model.gbm, valid.x)
pred.gbm = predict(modfit.gbm, valid.x)
confusionMatrix(pred.gbm, valid.x$classe)
confusionMatrix(valid.x$classe, pred.gbm)
cm.rf10 = confusionMatrix(valid1$classe, pred.rf10)
confusionMatrix(valid1$classe, pred.gbm)
(.packages())
library(gbm)
class(modfit.gbm)
mod1 = modfit.gbm
mod1 = as.data.frame(mod1)
class(modfit.gbm[1])
class(modfit.gbm[2])
class(modfit.gbm[20])
cm.gbm = confusionMatrix(valid1$classe, pred.gbm)
class(cm.gbm)
class(pred.gbm)
dim(pred.gbm)
length(pred.gbm)
?write
?write.csv2
write.csv2(x=pred.gbm, file = "predgbm.csv")
getwd()
write.csv2(x=pred.gbm, file = "C:/Users/Eugene/Desktop/Coursera/08 Practical Machine Learning/Project/predgbm.csv")
pred.gbm1 = read.csv2("predgbm.csv", sep=",")
View(pred.gbm)
View(pred.gbm1)
View(s.factor(pred.gbm1))
View(as.factor(pred.gbm1))
class(pred.gbm)
class(pred.gbm1)
View(as.factor(as.list(pred.gbm1)))
View(as.factor(as.vector(pred.gbm1)))
View(as.factor(as.atomic(pred.gbm1)))
?atomic
dim(pred.gbm1)
View(as.factor(pred.gbm1[1]))
View(as.factor(pred.gbm1$X.x))
View(pred.gbm1$X.x)
class(pred.gbm1$X.x)
write.csv2(x=cm.gbm, file = "C:/Users/Eugene/Desktop/Coursera/08 Practical Machine Learning/Project/cmgbm.csv")
confusionMatrix(valid1$classe, pred.gbm1)
confusionMatrix(valid1$classe, pred.gbm)
confusionMatrix(valid1$classe, pred.gbm1)
pred.gbm1[1]
pred.gbm1[[1]]
pred.gbm1[1,1]
pred.gbm1 = read.csv2("predgbm.csv", sep=";")
View(pred.gbm1)
pred.gbm1 = as.factor(pred.gbm1)
pred.gbm1 = as.factor(pred.gbm1$x)
View(pred.gbm1)
pred.gbm1 = read.csv2("predgbm.csv", sep=";")
pred.gbm1 = as.factor(pred.gbm1$x)
cm.gbm = confusionMatrix(valid1$classe, pred.gbm)
cm.gbm
modfit.nb = train(classe~.,data=train.xt, method="nb")
pred.nb = predict(modfit.nb, valid1)
cm.nb = confusionMatrix(valid1$classe, pred.nb)
cm.nb
write.csv2(x=pred.nb, file = "C:/Users/Eugene/Desktop/Coursera/08 Practical Machine Learning/Project/prednb.csv")
print(modfit.gbm)
plot(modfit.gbm)
plot(modfit.nb)
plot(modfit.rf)
plot(model.tree)
plot(modfit.XTrees)
cm.gbm = confusionMatrix(valid1$classe, pred.gbm)
modfit.lda = train(classe ~ .,data=train.xt, method="lda", trControl = trainControl(method = "cv", number = 10), allowParallel=T)
pred.lda = predict(modfit.lda, valid1)
modfit.lda = train(classe ~ .,data=train.xt, method="lda", trControl = trainControl(method = "boot632", number = 4), allowParallel=T)
pred.lda = predict(modfit.lda, valid1)
getwd()
write.csv2(x=pred.gbm, file = "C:/Users/Eugene/Desktop/Coursera/08 Practical Machine Learning/Project/predgbm.csv")
write.csv2(x=pred.lda, file = "C:/Users/Eugene/Desktop/Coursera/08 Practical Machine Learning/Project/predlda.csv")
library(klaR)
library(MASS)
library(caret)
library(knitr)
library(rJava)
library(extraTrees)
library(gplots)
library(rpart)
library(rattle)
library(tree)
library(gbm)
library(klaR)
library(MASS)
pred.lda = read.csv2("predlda.csv", sep=";")
pred.lda = predict(modfit.lda, valid1)
cm.lda = confusionMatrix(valid1$classe, pred.lda)
```
cm.XTrees = confusionMatrix(valid1$classe, pred.XTrees)
